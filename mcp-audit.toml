# MCP Audit Configuration File
# Last Updated: 2025-11-30
#
# This file defines pricing for AI models used in your sessions.
# All prices are in USD per million tokens.
#
# Pricing sources (verified 2025-11-30):
# - Anthropic: https://www.claude.com/pricing#api
# - OpenAI: https://openai.com/api/pricing/
# - Google: https://ai.google.dev/gemini-api/docs/pricing

# ============================================================================
# Claude Models (Anthropic)
# Pricing: https://www.claude.com/pricing#api
# ============================================================================

[pricing.claude]
# Claude Opus 4.5 (most capable, latest)
"claude-opus-4-5-20251101" = { input = 5.0, output = 25.0, cache_create = 6.25, cache_read = 0.50 }

# Claude Sonnet 4.5 (balanced performance)
"claude-sonnet-4-5-20250929" = { input = 3.0, output = 15.0, cache_create = 3.75, cache_read = 0.30 }

# Claude Haiku 4.5 (fastest, most cost-efficient)
"claude-haiku-4-5" = { input = 1.0, output = 5.0, cache_create = 1.25, cache_read = 0.10 }
"claude-haiku-4-5-20251001" = { input = 1.0, output = 5.0, cache_create = 1.25, cache_read = 0.10 }

# Legacy Claude Models
# Claude Opus 4.1
"claude-opus-4-1" = { input = 15.0, output = 75.0, cache_create = 18.75, cache_read = 1.50 }

# Claude Sonnet 4
"claude-sonnet-4-20250514" = { input = 3.0, output = 15.0, cache_create = 3.75, cache_read = 0.30 }

# Claude Opus 4
"claude-opus-4-20250514" = { input = 15.0, output = 75.0, cache_create = 18.75, cache_read = 1.50 }

# Claude Haiku 3.5
"claude-3-5-haiku-20241022" = { input = 0.80, output = 4.0, cache_create = 1.0, cache_read = 0.08 }

# ============================================================================
# OpenAI Models
# Pricing: https://openai.com/api/pricing/
# ============================================================================

[pricing.openai]
# GPT-5 Series (Latest)
"gpt-5.1" = { input = 1.25, output = 10.0, cache_read = 0.125 }
"gpt-5-mini" = { input = 0.25, output = 2.0, cache_read = 0.025 }
"gpt-5-nano" = { input = 0.05, output = 0.40, cache_read = 0.005 }
"gpt-5-pro" = { input = 15.0, output = 120.0 }

# Codex CLI Specific Models
"gpt-5.1-codex-max" = { input = 1.25, output = 10.0, cache_read = 0.125 }
"gpt-5-codex" = { input = 1.25, output = 10.0, cache_read = 0.125 }

# GPT-4.1 Series
"gpt-4.1" = { input = 3.0, output = 12.0, cache_read = 0.75 }
"gpt-4.1-mini" = { input = 0.80, output = 3.20, cache_read = 0.20 }
"gpt-4.1-nano" = { input = 0.20, output = 0.80, cache_read = 0.05 }

# O-Series (Reasoning Models)
"o4-mini" = { input = 4.0, output = 16.0, cache_read = 1.0 }
"o3-mini" = { input = 1.1, output = 4.4, cache_read = 0.55 }
"o1-preview" = { input = 15.0, output = 60.0, cache_read = 7.5 }
"o1-mini" = { input = 3.0, output = 12.0, cache_read = 1.5 }

# GPT-4o Series (Legacy)
"gpt-4o" = { input = 2.5, output = 10.0, cache_read = 1.25 }
"gpt-4o-mini" = { input = 0.15, output = 0.6, cache_read = 0.075 }

# ============================================================================
# Google Gemini Models
# Pricing: https://ai.google.dev/gemini-api/docs/pricing
# ============================================================================

[pricing.gemini]
# Gemini 3 Series (Latest)
"gemini-3-pro-preview" = { input = 2.0, output = 12.0, cache_create = 0.50, cache_read = 0.20 }

# Gemini 2.5 Series
"gemini-2.5-pro" = { input = 1.25, output = 10.0, cache_create = 0.3125, cache_read = 0.125 }
"gemini-2.5-pro-preview" = { input = 1.25, output = 10.0, cache_create = 0.3125, cache_read = 0.125 }
"gemini-2.5-flash" = { input = 0.30, output = 2.50, cache_create = 0.075, cache_read = 0.03 }
"gemini-2.5-flash-preview" = { input = 0.30, output = 2.50, cache_create = 0.075, cache_read = 0.03 }
"gemini-2.5-flash-lite" = { input = 0.10, output = 0.40, cache_create = 0.025, cache_read = 0.01 }

# Gemini 2.0 Series
"gemini-2.0-flash" = { input = 0.10, output = 0.40, cache_create = 0.025, cache_read = 0.025 }
"gemini-2.0-flash-lite" = { input = 0.075, output = 0.30, cache_create = 0.01875, cache_read = 0.01875 }

# ============================================================================
# Custom Models
# ============================================================================

[pricing.custom]
# Add your custom models here. Examples:
#
# Local models (no API cost):
# "llama-3-70b" = { input = 0.0, output = 0.0, cache_create = 0.0, cache_read = 0.0 }
#
# Custom API models:
# "my-fine-tuned-gpt4" = { input = 5.0, output = 20.0, cache_read = 2.5 }
#
# Format:
# "model-name" = { input = X.X, output = Y.Y, cache_create = Z.Z, cache_read = W.W }
#
# Note: cache_create and cache_read are optional if your model doesn't support caching

# ============================================================================
# Configuration Metadata
# ============================================================================

[metadata]
currency = "USD"
pricing_unit = "per_million_tokens"
last_updated = "2025-11-30"

# Exchange rates (optional - for display purposes only)
[metadata.exchange_rates]
USD_to_AUD = 1.54
USD_to_EUR = 0.92
USD_to_GBP = 0.79
