# Feature Reference

Complete reference for Token Audit features. For getting started, see [Getting Started](getting-started.md).

---

## Table of Contents

- [Real-Time TUI Dashboard](#real-time-tui-dashboard)
- [Smell Detection Engine](#smell-detection-engine)
- [Recommendations Engine](#recommendations-engine)
- [Multi-Model Tracking](#multi-model-tracking)
- [Dynamic Pricing](#dynamic-pricing)
- [Context Tax Tracking](#context-tax-tracking)
- [Zombie Tool Detection](#zombie-tool-detection)
- [Reports and Exports](#reports-and-exports)
- [Session Browser](#session-browser)
- [Theme System](#theme-system)

---

## Real-Time TUI Dashboard

The TUI (Terminal User Interface) provides live visibility into your AI coding session.

### Token Usage Panel

```
Token Usage
──────────────────────────────────────
Input:       45,231    Output:    12,345
Cached:     125,000    Total:    182,576
Token Rate: 15.2K/min  Call Rate: 3.2/min
```

| Metric | Description |
|--------|-------------|
| **Input** | Tokens sent to the model (prompts, context, tool inputs) |
| **Output** | Tokens generated by the model (responses, tool outputs) |
| **Cached** | Tokens served from cache (reduced cost) |
| **Total** | Sum of all token types |
| **Token Rate** | Session velocity — tokens consumed per minute |
| **Call Rate** | Tool activity rate — calls per minute |

**Rate metrics** (v0.7.0) help identify:
- High token rate → rapid context consumption, auto-compaction risk
- High call rate → chatty tool patterns, potential for batching

### MCP Servers Panel

```
MCP Servers (4 servers, 12 tools, 47 calls)
──────────────────────────────────────
  zen ............. 28 calls, 234K tokens
  brave-search .... 14 calls, 89K tokens
  backlog ......... 5 calls, 12K tokens
```

| Component | Description |
|-----------|-------------|
| **Servers** | Number of active MCP servers |
| **Tools** | Unique tools called (diversity metric) |
| **Calls** | Total MCP tool invocations |
| **Per-server breakdown** | Calls and tokens by server |

### Cost Panel

```
Cost: $0.42 (Estimated)
Cache Efficiency: 68.4%
Cache Hit: 72.1%
```

| Metric | Formula | Description |
|--------|---------|-------------|
| **Cost** | Based on model pricing | Estimated session spend |
| **Cache Efficiency** | Cost savings % | How much money cache saves |
| **Cache Hit** | `cache_read / (cache_read + input)` | What % of input from cache |

**Why both cache metrics?** High cache hit doesn't always mean high cost savings (depends on model pricing). Both together give the full picture.

---

## Smell Detection Engine

Automatically detect efficiency anti-patterns during sessions. Available since v0.5.0, expanded in v0.8.0.

### All 12 Smell Patterns

| Pattern | Severity | Threshold | What It Means |
|---------|----------|-----------|---------------|
| `HIGH_VARIANCE` | warning | CV > 50% | Token counts vary wildly — consider batching |
| `TOP_CONSUMER` | info | >50% of tokens | Single tool dominates — investigate or optimize |
| `HIGH_MCP_SHARE` | info | >80% of tokens | Heavy MCP reliance — consider built-in alternatives |
| `CHATTY` | warning | >20 calls | Too many calls — consider batching or caching |
| `LOW_CACHE_HIT` | warning | <30% ratio | Cache underutilized — reorder operations for reuse |
| `REDUNDANT_CALLS` | warning | Same params | Identical tool calls — implement caching |
| `EXPENSIVE_FAILURES` | error | High-token errors | Tools consuming tokens but failing |
| `UNDERUTILIZED_SERVER` | info | <10% utilization | MCP server barely used — consider removing |
| `BURST_PATTERN` | warning | >5 calls/second | Potential loops — investigate rapid calls |
| `LARGE_PAYLOAD` | warning | >10K tokens | Single call very large — consider chunking |
| `SEQUENTIAL_READS` | info | Multiple files | Could be batched into single operation |
| `CACHE_MISS_STREAK` | warning | 5+ misses | Consecutive cache misses — pattern issue |

### Smells in Session Data

Detected smells are saved with each session:

```json
{
  "smells": [
    {
      "pattern": "CHATTY",
      "severity": "warning",
      "tool": "mcp__zen__chat",
      "description": "Called 25 times",
      "evidence": {"call_count": 25, "threshold": 20}
    }
  ]
}
```

### Viewing Smells

```bash
# Cross-session smell analysis (last 30 days)
token-audit report --smells

# Filter by days and platform
token-audit report --smells --days 7 --platform claude-code

# Export as JSON
token-audit report --smells --format json --output smells.json

# Filter by minimum frequency
token-audit report --smells --min-frequency 10
```

| Option | Default | Description |
|--------|---------|-------------|
| `--days` | 30 | Number of days to analyze |
| `--platform` | *(all)* | Filter: claude-code, codex-cli, gemini-cli |
| `--project` | *(all)* | Filter by project name |
| `--format` | text | Output: text, json, markdown |
| `--min-frequency` | 0 | Minimum frequency % to display |

---

## Recommendations Engine

Converts detected smells into actionable recommendations (v0.8.0).

### Recommendation Types

| Type | Triggered By | Action |
|------|--------------|--------|
| `REMOVE_UNUSED_SERVER` | UNDERUTILIZED_SERVER | Remove MCP server from config |
| `ENABLE_CACHING` | LOW_CACHE_HIT, REDUNDANT_CALLS | Improve cache utilization |
| `BATCH_OPERATIONS` | CHATTY, SEQUENTIAL_READS | Combine multiple calls |
| `OPTIMIZE_COST` | TOP_CONSUMER, EXPENSIVE_FAILURES | Reduce token consumption |

### Recommendations in Session Data

```json
{
  "recommendations": [
    {
      "type": "REMOVE_UNUSED_SERVER",
      "confidence": 0.85,
      "server": "unused-mcp-server",
      "evidence_summary": "Server has 0 calls across 5 sessions"
    }
  ]
}
```

### Using with AI Analysis

Export recommendations for AI-assisted review:

```bash
token-audit report --format ai
```

The export includes recommendations with evidence for AI interpretation.

---

## Multi-Model Tracking

Track sessions that switch between models (v0.6.0).

### Per-Model Breakdown

When a session uses multiple models (e.g., switching from Sonnet to Haiku):

```
Models Used: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
───────────────────────────────────────────────────────────────
Model                          Input      Output    Cost
claude-3-5-sonnet-20241022     45,231     12,345    $0.2134
claude-3-5-haiku-20241022      8,765      2,100     $0.0087
```

### Session Data Format

```json
{
  "models_used": ["claude-3-5-sonnet-20241022", "claude-3-5-haiku-20241022"],
  "model_usage": {
    "claude-3-5-sonnet-20241022": {
      "input_tokens": 45231,
      "output_tokens": 12345,
      "cost_usd": 0.2134,
      "call_count": 15
    }
  }
}
```

### Supported Models

Token Audit tracks 2,000+ models via LiteLLM pricing:
- **Anthropic**: Claude Opus 4.5, Sonnet 4.5, Haiku 3.5, and all previous versions
- **OpenAI**: GPT-4o, GPT-5.1, O-series (with reasoning tokens)
- **Google**: Gemini 2.0 Pro, Flash (with reasoning tokens)

---

## Dynamic Pricing

Auto-fetch current model pricing for accurate cost estimates (v0.6.0).

### How It Works

1. **Primary**: Fetch from [LiteLLM pricing database](https://github.com/BerriAI/litellm) (2,000+ models)
2. **Cache**: Store locally for 24 hours (configurable)
3. **Fallback**: Use TOML config or built-in defaults

### Data Quality Tracking

Session logs include pricing source:

```json
{
  "data_quality": {
    "pricing_source": "api",
    "pricing_freshness": "fresh"
  }
}
```

| Source | Description |
|--------|-------------|
| `api` | Fresh from LiteLLM API |
| `cache` | Valid cached data |
| `toml` | From configuration file |
| `built-in` | Hardcoded defaults |

### Check Pricing Status

```bash
token-audit tokenizer setup
```

See [Configuration Reference](configuration.md#pricing-configuration) for customization.

---

## Context Tax Tracking

Measure static token overhead from MCP server schemas (v0.6.0).

### What is Context Tax?

Every MCP server consumes tokens just by existing:
- Tool schemas are loaded into context
- This happens before any work begins
- More servers = more "tax" on your context window

### TUI Panel

```
Context Tax
─────────────────────────────────────
Total: 6,450 tokens (static overhead)

Per Server:
  zen ............. 3,000 tokens
  backlog ......... 2,250 tokens
  brave-search .... 1,200 tokens

Zombie Tax: +450 tokens (unused tools)
```

### Known Servers Database

Pre-measured token counts for popular servers:

| Server | Tools | Estimated Tokens |
|--------|-------|------------------|
| `zen` | 12 | ~3,000 |
| `backlog` | 15 | ~2,250 |
| `brave-search` | 6 | ~1,200 |
| `jina` | 20 | ~3,600 |
| `context7` | 5 | ~750 |

Unknown servers: estimate 10 tools × 175 tokens/tool.

---

## Zombie Tool Detection

Identify MCP tools defined but never used (v0.5.0).

### Configuration

```toml
# token-audit.toml
[zombie_tools.zen]
tools = [
    "mcp__zen__thinkdeep",
    "mcp__zen__debug",
    "mcp__zen__refactor"
]
```

### How It Works

1. Configure known tools per server
2. Token Audit tracks which tools are called
3. Unused tools are reported as "zombies"

### Session Data

```json
{
  "zombie_tools": {
    "zen": ["mcp__zen__refactor", "mcp__zen__precommit"]
  }
}
```

### Why It Matters

Each unused tool's schema contributes to context overhead without value. Removing zombie tools reduces your context tax.

---

## Reports and Exports

Generate post-session analysis and exports.

### Report Command

```bash
# Basic report (markdown)
token-audit report ~/.token-audit/sessions/

# Top 5 tools only
token-audit report --top-n 5

# JSON format
token-audit report --format json

# CSV for spreadsheet analysis
token-audit report --format csv --output analysis.csv

# Aggregate across sessions
token-audit report --aggregate
```

### Export for AI Analysis

```bash
# Markdown (default) — paste into Claude/ChatGPT
token-audit report --format ai

# JSON for programmatic use
token-audit report --format ai-json

# Specific session
token-audit report path/to/session.json --format ai
```

The AI export includes:
- Session summary (tokens, costs, duration)
- Top tools by consumption
- Detected smells with evidence
- Recommendations
- Suggested analysis questions

### Sample AI Prompts

After exporting, try these prompts:
- "Analyze this session for optimization opportunities"
- "What patterns suggest context bloat?"
- "Recommend changes to my MCP configuration"

---

## Session Browser

Interactive TUI for browsing past sessions. **v1.0.0** introduces a Dashboard view as the default landing page.

### Launch

```bash
token-audit ui                              # Launch to Dashboard (default)
token-audit ui --view sessions              # Start in session list
token-audit ui --view live                  # Start in live monitoring
token-audit ui --view recommendations       # Start in recommendations
token-audit ui --compact                    # Force compact mode
token-audit ui --theme mocha                # Use specific theme
```

### Views (v1.0.0)

| View | Key | Description |
|------|-----|-------------|
| **Dashboard** | `1` | Today's summary, weekly trends, top smells, recent sessions |
| **Sessions** | `2` | Full session list with filtering and sorting |
| **Recommendations** | `3` | Actionable optimization suggestions grouped by confidence |
| **Live** | `4` | Real-time session monitoring with token burn rate |

### Keybindings

| Key | Action |
|-----|--------|
| `1`-`4` | Switch between views |
| `j/k`, `↑/↓` | Navigate |
| `Enter` | View details / Select |
| `:` | Command palette (quick navigation) |
| `/` | Search sessions |
| `f` | Cycle platform filter |
| `s` | Cycle sort (date/cost/duration/tools) |
| `a` | Export to AI |
| `p` | Pin/unpin session |
| `r` | Refresh |
| `?` | Show help |
| `Esc` | Back / Navigate back (uses breadcrumb history) |
| `q` | Quit |

### Navigation Features (v1.0.0)

#### Breadcrumb Navigation

The TUI tracks your navigation history, showing your current path in the header:

```
Dashboard > Sessions > session-abc123
```

Use `Esc` or `←` to navigate back through your history. The breadcrumb updates automatically as you navigate.

#### Refresh Indicator

The header shows when data was last refreshed:

```
Token Audit v1.0.0 | Sessions: 15 | Last refresh: 2m ago
```

| State | Display |
|-------|---------|
| Just refreshed | `Last refresh: just now` |
| Refreshing | `⟳ Refreshing...` |
| Stale (>5 min) | `Last refresh: 8m ago ⚠` (yellow warning) |

Press `r` to refresh session data manually.

#### First-Run Help Hints

New users (first 3 launches) see contextual help hints in the footer:

```
[?] Press ? for help  |  j/k=nav  Enter=view  :=cmd  r=refresh
```

These hints automatically disappear after a few sessions.

#### Accuracy Legend

The session list header includes an accuracy indicator legend:

```
Sessions (15)  |  Accuracy: ✓=exact ~=estimated •=calls-only
```

This helps users understand token count precision for each session.

### Command Palette

Press `:` to open the command palette for quick navigation:

```
: dashboard
─────────────────────────────────────────
> dashboard     Overview and quick stats
  sessions      Browse all sessions
  recommendations Optimization suggestions
  live          Real-time monitoring
  help          Show help
```

Type to fuzzy-match, press Enter to select, Esc to cancel.

### Compact Mode

Narrow terminals auto-detect compact mode, or force it with `--compact`:

| Wide (>100 cols) | Compact (<100 cols) |
|------------------|---------------------|
| `2025-12-19` | `12/19` |
| `claude-code` | `claude` |
| `45,231 tokens` | `45K` |

### Filtering & Sorting

- **Platform filter**: Show only Claude Code, Codex CLI, or Gemini CLI sessions
- **Sort order**: By date, cost, duration, or tool count
- **Pinned sessions**: Keep important sessions at top

---

## Theme System

Customize the TUI appearance.

### Available Themes

| Theme | Description |
|-------|-------------|
| `auto` | Detect terminal preference (default) |
| `dark` | Standard dark theme |
| `light` | Standard light theme |
| `mocha` | Catppuccin Mocha (warm dark) |
| `latte` | Catppuccin Latte (warm light) |
| `hc-dark` | High contrast dark (WCAG AAA) |
| `hc-light` | High contrast light (WCAG AAA) |

### Usage

```bash
# Set theme per session
token-audit collect --theme mocha

# Session browser
token-audit ui --theme hc-dark
```

### Accessibility

- **NO_COLOR**: Respects the [NO_COLOR](https://no-color.org/) standard
- **ASCII mode**: `--plain` for CI/pipelines without unicode
- **High contrast**: WCAG AAA compliant themes for visual accessibility

---

## Platform Capabilities

Feature availability varies by platform:

| Feature | Claude Code | Codex CLI | Gemini CLI |
|---------|:-----------:|:---------:|:----------:|
| Session tokens | ✅ Native | ✅ Estimated (99%) | ✅ Estimated (100%) |
| Per-tool tokens | ✅ Native | ✅ Estimated | ✅ Estimated |
| Reasoning tokens | ❌ | ✅ O-series | ✅ Gemini 2.0+ |
| Cache tracking | ✅ Full | ✅ Read only | ✅ Read only |
| Multi-model | ✅ | ✅ | ✅ |

See platform guides for details:
- [Claude Code](platforms/claude-code.md)
- [Codex CLI](platforms/codex-cli.md)
- [Gemini CLI](platforms/gemini-cli.md)

---

*For configuration options, see [Configuration Reference](configuration.md). For issues, see [Troubleshooting](troubleshooting.md).*
