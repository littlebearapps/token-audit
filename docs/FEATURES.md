# Feature Reference

Complete reference for MCP Audit features. For getting started, see [Getting Started](GETTING-STARTED.md).

---

## Table of Contents

- [Real-Time TUI Dashboard](#real-time-tui-dashboard)
- [Smell Detection Engine](#smell-detection-engine)
- [Recommendations Engine](#recommendations-engine)
- [Multi-Model Tracking](#multi-model-tracking)
- [Dynamic Pricing](#dynamic-pricing)
- [Context Tax Tracking](#context-tax-tracking)
- [Zombie Tool Detection](#zombie-tool-detection)
- [Reports and Exports](#reports-and-exports)
- [Session Browser](#session-browser)
- [Theme System](#theme-system)

---

## Real-Time TUI Dashboard

The TUI (Terminal User Interface) provides live visibility into your AI coding session.

### Token Usage Panel

```
Token Usage
──────────────────────────────────────
Input:       45,231    Output:    12,345
Cached:     125,000    Total:    182,576
Token Rate: 15.2K/min  Call Rate: 3.2/min
```

| Metric | Description |
|--------|-------------|
| **Input** | Tokens sent to the model (prompts, context, tool inputs) |
| **Output** | Tokens generated by the model (responses, tool outputs) |
| **Cached** | Tokens served from cache (reduced cost) |
| **Total** | Sum of all token types |
| **Token Rate** | Session velocity — tokens consumed per minute |
| **Call Rate** | Tool activity rate — calls per minute |

**Rate metrics** (v0.7.0) help identify:
- High token rate → rapid context consumption, auto-compaction risk
- High call rate → chatty tool patterns, potential for batching

### MCP Servers Panel

```
MCP Servers (4 servers, 12 tools, 47 calls)
──────────────────────────────────────
  zen ............. 28 calls, 234K tokens
  brave-search .... 14 calls, 89K tokens
  backlog ......... 5 calls, 12K tokens
```

| Component | Description |
|-----------|-------------|
| **Servers** | Number of active MCP servers |
| **Tools** | Unique tools called (diversity metric) |
| **Calls** | Total MCP tool invocations |
| **Per-server breakdown** | Calls and tokens by server |

### Cost Panel

```
Cost: $0.42 (Estimated)
Cache Efficiency: 68.4%
Cache Hit: 72.1%
```

| Metric | Formula | Description |
|--------|---------|-------------|
| **Cost** | Based on model pricing | Estimated session spend |
| **Cache Efficiency** | Cost savings % | How much money cache saves |
| **Cache Hit** | `cache_read / (cache_read + input)` | What % of input from cache |

**Why both cache metrics?** High cache hit doesn't always mean high cost savings (depends on model pricing). Both together give the full picture.

---

## Smell Detection Engine

Automatically detect efficiency anti-patterns during sessions. Available since v0.5.0, expanded in v0.8.0.

### All 12 Smell Patterns

| Pattern | Severity | Threshold | What It Means |
|---------|----------|-----------|---------------|
| `HIGH_VARIANCE` | warning | CV > 50% | Token counts vary wildly — consider batching |
| `TOP_CONSUMER` | info | >50% of tokens | Single tool dominates — investigate or optimize |
| `HIGH_MCP_SHARE` | info | >80% of tokens | Heavy MCP reliance — consider built-in alternatives |
| `CHATTY` | warning | >20 calls | Too many calls — consider batching or caching |
| `LOW_CACHE_HIT` | warning | <30% ratio | Cache underutilized — reorder operations for reuse |
| `REDUNDANT_CALLS` | warning | Same params | Identical tool calls — implement caching |
| `EXPENSIVE_FAILURES` | error | High-token errors | Tools consuming tokens but failing |
| `UNDERUTILIZED_SERVER` | info | <10% utilization | MCP server barely used — consider removing |
| `BURST_PATTERN` | warning | >5 calls/second | Potential loops — investigate rapid calls |
| `LARGE_PAYLOAD` | warning | >10K tokens | Single call very large — consider chunking |
| `SEQUENTIAL_READS` | info | Multiple files | Could be batched into single operation |
| `CACHE_MISS_STREAK` | warning | 5+ misses | Consecutive cache misses — pattern issue |

### Smells in Session Data

Detected smells are saved with each session:

```json
{
  "smells": [
    {
      "pattern": "CHATTY",
      "severity": "warning",
      "tool": "mcp__zen__chat",
      "description": "Called 25 times",
      "evidence": {"call_count": 25, "threshold": 20}
    }
  ]
}
```

### Viewing Smells

```bash
# Cross-session smell analysis
mcp-audit smells ~/.mcp-audit/sessions/

# Filter by severity
mcp-audit smells --severity warning

# Filter by pattern
mcp-audit smells --pattern CHATTY
```

---

## Recommendations Engine

Converts detected smells into actionable recommendations (v0.8.0).

### Recommendation Types

| Type | Triggered By | Action |
|------|--------------|--------|
| `REMOVE_UNUSED_SERVER` | UNDERUTILIZED_SERVER | Remove MCP server from config |
| `ENABLE_CACHING` | LOW_CACHE_HIT, REDUNDANT_CALLS | Improve cache utilization |
| `BATCH_OPERATIONS` | CHATTY, SEQUENTIAL_READS | Combine multiple calls |
| `OPTIMIZE_COST` | TOP_CONSUMER, EXPENSIVE_FAILURES | Reduce token consumption |

### Recommendations in Session Data

```json
{
  "recommendations": [
    {
      "type": "REMOVE_UNUSED_SERVER",
      "confidence": 0.85,
      "server": "unused-mcp-server",
      "evidence_summary": "Server has 0 calls across 5 sessions"
    }
  ]
}
```

### Using with AI Analysis

Export recommendations for AI-assisted review:

```bash
mcp-audit export ai-prompt
```

The export includes recommendations with evidence for AI interpretation.

---

## Multi-Model Tracking

Track sessions that switch between models (v0.6.0).

### Per-Model Breakdown

When a session uses multiple models (e.g., switching from Sonnet to Haiku):

```
Models Used: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
───────────────────────────────────────────────────────────────
Model                          Input      Output    Cost
claude-3-5-sonnet-20241022     45,231     12,345    $0.2134
claude-3-5-haiku-20241022      8,765      2,100     $0.0087
```

### Session Data Format

```json
{
  "models_used": ["claude-3-5-sonnet-20241022", "claude-3-5-haiku-20241022"],
  "model_usage": {
    "claude-3-5-sonnet-20241022": {
      "input_tokens": 45231,
      "output_tokens": 12345,
      "cost_usd": 0.2134,
      "call_count": 15
    }
  }
}
```

### Supported Models

MCP Audit tracks 2,000+ models via LiteLLM pricing:
- **Anthropic**: Claude Opus 4.5, Sonnet 4.5, Haiku 3.5, and all previous versions
- **OpenAI**: GPT-4o, GPT-5.1, O-series (with reasoning tokens)
- **Google**: Gemini 2.0 Pro, Flash (with reasoning tokens)

---

## Dynamic Pricing

Auto-fetch current model pricing for accurate cost estimates (v0.6.0).

### How It Works

1. **Primary**: Fetch from [LiteLLM pricing database](https://github.com/BerriAI/litellm) (2,000+ models)
2. **Cache**: Store locally for 24 hours (configurable)
3. **Fallback**: Use TOML config or built-in defaults

### Data Quality Tracking

Session logs include pricing source:

```json
{
  "data_quality": {
    "pricing_source": "api",
    "pricing_freshness": "fresh"
  }
}
```

| Source | Description |
|--------|-------------|
| `api` | Fresh from LiteLLM API |
| `cache` | Valid cached data |
| `toml` | From configuration file |
| `built-in` | Hardcoded defaults |

### Check Pricing Status

```bash
mcp-audit init
```

See [Configuration Reference](CONFIGURATION.md#pricing-configuration) for customization.

---

## Context Tax Tracking

Measure static token overhead from MCP server schemas (v0.6.0).

### What is Context Tax?

Every MCP server consumes tokens just by existing:
- Tool schemas are loaded into context
- This happens before any work begins
- More servers = more "tax" on your context window

### TUI Panel

```
Context Tax
─────────────────────────────────────
Total: 6,450 tokens (static overhead)

Per Server:
  zen ............. 3,000 tokens
  backlog ......... 2,250 tokens
  brave-search .... 1,200 tokens

Zombie Tax: +450 tokens (unused tools)
```

### Known Servers Database

Pre-measured token counts for popular servers:

| Server | Tools | Estimated Tokens |
|--------|-------|------------------|
| `zen` | 12 | ~3,000 |
| `backlog` | 15 | ~2,250 |
| `brave-search` | 6 | ~1,200 |
| `jina` | 20 | ~3,600 |
| `context7` | 5 | ~750 |

Unknown servers: estimate 10 tools × 175 tokens/tool.

---

## Zombie Tool Detection

Identify MCP tools defined but never used (v0.5.0).

### Configuration

```toml
# mcp-audit.toml
[zombie_tools.zen]
tools = [
    "mcp__zen__thinkdeep",
    "mcp__zen__debug",
    "mcp__zen__refactor"
]
```

### How It Works

1. Configure known tools per server
2. MCP Audit tracks which tools are called
3. Unused tools are reported as "zombies"

### Session Data

```json
{
  "zombie_tools": {
    "zen": ["mcp__zen__refactor", "mcp__zen__precommit"]
  }
}
```

### Why It Matters

Each unused tool's schema contributes to context overhead without value. Removing zombie tools reduces your context tax.

---

## Reports and Exports

Generate post-session analysis and exports.

### Report Command

```bash
# Basic report (markdown)
mcp-audit report ~/.mcp-audit/sessions/

# Top 5 tools only
mcp-audit report --top-n 5

# JSON format
mcp-audit report --format json

# CSV for spreadsheet analysis
mcp-audit report --format csv --output analysis.csv

# Aggregate across sessions
mcp-audit report --aggregate
```

### Export for AI Analysis

```bash
# Markdown (default) — paste into Claude/ChatGPT
mcp-audit export ai-prompt

# JSON for programmatic use
mcp-audit export ai-prompt --format json

# Specific session
mcp-audit export ai-prompt path/to/session.json
```

The AI export includes:
- Session summary (tokens, costs, duration)
- Top tools by consumption
- Detected smells with evidence
- Recommendations
- Suggested analysis questions

### Sample AI Prompts

After exporting, try these prompts:
- "Analyze this session for optimization opportunities"
- "What patterns suggest context bloat?"
- "Recommend changes to my MCP configuration"

---

## Session Browser

Interactive TUI for browsing past sessions.

### Launch

```bash
mcp-audit ui
mcp-audit ui --theme mocha
```

### Keybindings

| Key | Action |
|-----|--------|
| `j/k`, `↑/↓` | Navigate sessions |
| `Enter` | View session details |
| `f` | Cycle platform filter |
| `s` | Cycle sort (date/cost/duration/tools) |
| `p` | Pin/unpin session |
| `r` | Refresh list |
| `?` | Show help |
| `q` | Quit |

### Filtering & Sorting

- **Platform filter**: Show only Claude Code, Codex CLI, or Gemini CLI sessions
- **Sort order**: By date, cost, duration, or tool count
- **Pinned sessions**: Keep important sessions at top

---

## Theme System

Customize the TUI appearance.

### Available Themes

| Theme | Description |
|-------|-------------|
| `auto` | Detect terminal preference (default) |
| `dark` | Standard dark theme |
| `light` | Standard light theme |
| `mocha` | Catppuccin Mocha (warm dark) |
| `latte` | Catppuccin Latte (warm light) |
| `hc-dark` | High contrast dark (WCAG AAA) |
| `hc-light` | High contrast light (WCAG AAA) |

### Usage

```bash
# Set theme per session
mcp-audit collect --theme mocha

# Session browser
mcp-audit ui --theme hc-dark
```

### Accessibility

- **NO_COLOR**: Respects the [NO_COLOR](https://no-color.org/) standard
- **ASCII mode**: `--plain` for CI/pipelines without unicode
- **High contrast**: WCAG AAA compliant themes for visual accessibility

---

## Platform Capabilities

Feature availability varies by platform:

| Feature | Claude Code | Codex CLI | Gemini CLI |
|---------|:-----------:|:---------:|:----------:|
| Session tokens | ✅ Native | ✅ Estimated (99%) | ✅ Estimated (100%) |
| Per-tool tokens | ✅ Native | ✅ Estimated | ✅ Estimated |
| Reasoning tokens | ❌ | ✅ O-series | ✅ Gemini 2.0+ |
| Cache tracking | ✅ Full | ✅ Read only | ✅ Read only |
| Multi-model | ✅ | ✅ | ✅ |

See platform guides for details:
- [Claude Code](platforms/claude-code.md)
- [Codex CLI](platforms/codex-cli.md)
- [Gemini CLI](platforms/gemini-cli.md)

---

*For configuration options, see [Configuration Reference](CONFIGURATION.md). For issues, see [Troubleshooting](TROUBLESHOOTING.md).*
